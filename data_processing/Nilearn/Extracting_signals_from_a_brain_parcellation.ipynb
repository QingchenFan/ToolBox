{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T07:00:32.328906Z",
     "start_time": "2024-06-27T07:00:30.848437Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qingchen/anaconda3/lib/python3.10/site-packages/nilearn/input_data/__init__.py:23: FutureWarning: The import path 'nilearn.input_data' is deprecated in version 0.9. Importing from 'nilearn.input_data' will be possible at least until release 0.13.0. Please import from 'nilearn.maskers' instead.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from nilearn.input_data import NiftiMasker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atlas ROIs are located in nifti image (4D) at: \n",
      "<class 'nibabel.nifti1.Nifti1Image'>\n",
      "data shape (91, 109, 91)\n",
      "affine:\n",
      "[[   2.    0.    0.  -90.]\n",
      " [   0.    2.    0. -126.]\n",
      " [   0.    0.    2.  -72.]\n",
      " [   0.    0.    0.    1.]]\n",
      "metadata:\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b''\n",
      "dim_info        : 0\n",
      "dim             : [  3  91 109  91   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : uint8\n",
      "bitpix          : 8\n",
      "slice_start     : 0\n",
      "pixdim          : [1. 2. 2. 2. 1. 1. 1. 1.]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 0\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b''\n",
      "aux_file        : b''\n",
      "qform_code      : unknown\n",
      "sform_code      : aligned\n",
      "quatern_b       : 0.0\n",
      "quatern_c       : 0.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : -90.0\n",
      "qoffset_y       : -126.0\n",
      "qoffset_z       : -72.0\n",
      "srow_x          : [  2.   0.   0. -90.]\n",
      "srow_y          : [   0.    2.    0. -126.]\n",
      "srow_z          : [  0.   0.   2. -72.]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nilearn import datasets\n",
    "\n",
    "dataset = datasets.fetch_atlas_harvard_oxford(\"cort-maxprob-thr25-2mm\")\n",
    "atlas_filename = dataset.maps\n",
    "labels = dataset.labels\n",
    "\n",
    "print(f\"Atlas ROIs are located in nifti image (4D) at: {atlas_filename}\")\n",
    "\n",
    "# One subject of brain development fMRI data\n",
    "data = datasets.fetch_development_fmri(n_subjects=1, reduce_confounds=True)\n",
    "fmri_filenames = data.func[0]\n",
    "reduced_confounds = data.confounds[0]  # This is a preselected set of confounds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T07:00:38.266781Z",
     "start_time": "2024-06-27T07:00:38.247042Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'func': ['/Users/qingchen/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'], 'confounds': ['/Users/qingchen/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_desc-reducedConfounds_regressors.tsv'], 'phenotypic': array([('sub-pixar123', 27.06, 'Adult', 'adult', 'F', 'R')],\n",
      "      dtype=[('participant_id', '<U12'), ('Age', '<f8'), ('AgeGroup', '<U6'), ('Child_Adult', '<U5'), ('Gender', '<U4'), ('Handedness', '<U4')]), 'description': \"The movie watching based brain development dataset (fMRI)\\n\\n\\nNotes\\n-----\\nThis functional MRI dataset is used for teaching how to use\\nmachine learning to predict age from naturalistic stimuli (movie)\\nwatching with Nilearn.\\n\\nThe dataset consists of 50 children (ages 3-13) and 33 young adults (ages\\n18-39). This dataset can be used to try to predict who are adults and\\nwho are children.\\n\\nThe data is downsampled to 4mm resolution for convenience. The original\\ndata is downloaded from OpenNeuro.\\n\\nFor full information about pre-processing steps on raw-fMRI data, have a look\\nat README at https://osf.io/wjtyq/\\n\\nFull pre-processed data: https://osf.io/5hju4/files/\\n\\nRaw data can be accessed from : https://openneuro.org/datasets/ds000228/versions/1.0.0\\n\\nContent\\n-------\\n    :'func': functional MRI Nifti images (4D) per subject\\n    :'confounds': TSV file contain nuisance information per subject\\n    :'phenotypic': Phenotypic information for each subject such as age,\\n                   age group, gender, handedness.\\n\\n\\nReferences\\n----------\\nPlease cite this paper if you are using this dataset:\\nRichardson, H., Lisandrelli, G., Riobueno-Naylor, A., & Saxe, R. (2018).\\nDevelopment of the social brain from age three to twelve years.\\nNature communications, 9(1), 1027.\\nhttps://www.nature.com/articles/s41467-018-03399-2\\n\\nLicence: usage is unrestricted for non-commercial research purposes.\\n\"}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T07:01:46.278283Z",
     "start_time": "2024-06-27T07:01:46.273841Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/qingchen/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n"
     ]
    }
   ],
   "source": [
    "print(fmri_filenames)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T07:08:15.444571Z",
     "start_time": "2024-06-27T07:08:15.438844Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/qingchen/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_desc-reducedConfounds_regressors.tsv\n"
     ]
    }
   ],
   "source": [
    "print(reduced_confounds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T07:08:19.042302Z",
     "start_time": "2024-06-27T07:08:19.035791Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NiftiLabelsMasker.wrapped] loading data from Nifti1Image(\n",
      "shape=(91, 109, 91),\n",
      "affine=array([[   2.,    0.,    0.,  -90.],\n",
      "       [   0.,    2.,    0., -126.],\n",
      "       [   0.,    0.,    2.,  -72.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "Resampling labels\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.maskers.base_masker._filter_and_extract...\n",
      "_filter_and_extract('/Users/qingchen/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz', \n",
      "<nilearn.maskers.nifti_labels_masker._ExtractionFunctor object at 0x15e103400>, { 'background_label': 0,\n",
      "  'clean_kwargs': {},\n",
      "  'detrend': False,\n",
      "  'dtype': None,\n",
      "  'high_pass': None,\n",
      "  'high_variance_confounds': False,\n",
      "  'labels': None,\n",
      "  'labels_img': <nibabel.nifti1.Nifti1Image object at 0x107f63a60>,\n",
      "  'low_pass': None,\n",
      "  'mask_img': None,\n",
      "  'reports': True,\n",
      "  'smoothing_fwhm': None,\n",
      "  'standardize': 'zscore_sample',\n",
      "  'standardize_confounds': 'zscore_sample',\n",
      "  'strategy': 'mean',\n",
      "  't_r': None,\n",
      "  'target_affine': None,\n",
      "  'target_shape': None}, confounds=[ '/Users/qingchen/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_desc-reducedConfounds_regressors.tsv'], sample_mask=None, dtype=None, memory=Memory(location=nilearn_cache/joblib), memory_level=1, verbose=5)\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from /Users/qingchen/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "_______________________________________________filter_and_extract - 1.0s, 0.0min\n"
     ]
    }
   ],
   "source": [
    "from nilearn.maskers import NiftiLabelsMasker\n",
    "\n",
    "masker = NiftiLabelsMasker(\n",
    "    labels_img=atlas_filename,\n",
    "    standardize=\"zscore_sample\",\n",
    "    standardize_confounds=\"zscore_sample\",\n",
    "    memory=\"nilearn_cache\",\n",
    "    verbose=5,\n",
    ")\n",
    "\n",
    "# Here we go from nifti files to the signal time series in a numpy\n",
    "# array. Note how we give confounds to be regressed out during signal\n",
    "# extraction\n",
    "time_series = masker.fit_transform(fmri_filenames, confounds=reduced_confounds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T07:09:14.965548Z",
     "start_time": "2024-06-27T07:09:13.360759Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qingchen/anaconda3/lib/python3.10/site-packages/nilearn/connectome/connectivity_matrices.py:495: FutureWarning: The default strategy for standardize is currently 'zscore' which incorrectly uses population std to calculate sample zscores. The new strategy 'zscore_sample' corrects this behavior by using the sample std. In release 0.13, the default strategy will be replaced by the new strategy and the 'zscore' option will be removed. Please use 'zscore_sample' instead.\n",
      "  covariances_std = [\n"
     ]
    }
   ],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "correlation_measure = ConnectivityMeasure(\n",
    "    kind=\"correlation\",\n",
    "    #standardize=\"zscore_sample\",\n",
    ")\n",
    "correlation_matrix = correlation_measure.fit_transform([time_series])[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T07:11:31.064661Z",
     "start_time": "2024-06-27T07:11:31.058185Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from nilearn.interfaces.fmriprep import load_confounds\n",
    "import numpy as np\n",
    "\n",
    "from nilearn import plotting\n",
    "confounds_simple, sample_mask = load_confounds(\n",
    "    fmri_filenames,\n",
    "    strategy=[\"high_pass\", \"motion\", \"wm_csf\"],\n",
    "    motion=\"basic\",\n",
    "    wm_csf=\"basic\",\n",
    ")\n",
    "\n",
    "print(\"The shape of the confounds matrix is:\", confounds_simple.shape)\n",
    "print(confounds_simple.columns)\n",
    "\n",
    "time_series = masker.fit_transform(\n",
    "    fmri_filenames, confounds=confounds_simple, sample_mask=sample_mask\n",
    ")\n",
    "\n",
    "correlation_matrix = correlation_measure.fit_transform([time_series])[0]\n",
    "\n",
    "np.fill_diagonal(correlation_matrix, 0)\n",
    "\n",
    "plotting.plot_matrix(\n",
    "    correlation_matrix,\n",
    "    figure=(10, 8),\n",
    "    labels=labels[1:],\n",
    "    vmax=0.8,\n",
    "    vmin=-0.8,\n",
    "    title=\"Motion, WM, CSF\",\n",
    "    reorder=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
