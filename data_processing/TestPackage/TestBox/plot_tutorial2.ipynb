{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Tutorial 2: Customizing and aligning gradients\n",
    "In this tutorial you’ll learn about the methods available within the\n",
    "GradientMaps class. The flexible usage of this class allows for the\n",
    "customization of gradient computation with different kernels and dimensionality\n",
    "reductions, as well as aligning gradients from different datasets. This\n",
    "tutorial will only show you how to apply these techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing gradient computation\n",
    "As before, we’ll start by loading the sample data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T06:25:03.927558Z",
     "start_time": "2024-06-11T06:24:55.289033Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mbrainspace\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_group_fc, load_parcellation, load_conte69\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# First load mean connectivity matrix and Schaefer parcellation\u001B[39;00m\n\u001B[1;32m      4\u001B[0m conn_matrix \u001B[38;5;241m=\u001B[39m load_group_fc(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mschaefer\u001B[39m\u001B[38;5;124m'\u001B[39m, scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m400\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/brainspace/datasets/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (load_conte69, load_mask, load_group_fc, load_group_mpc,\n\u001B[1;32m      2\u001B[0m                    load_parcellation, load_gradient, load_marker, load_fsa5,\n\u001B[1;32m      3\u001B[0m                    load_confounds_preprocessing,\n\u001B[1;32m      4\u001B[0m                    fetch_timeseries_preprocessing)\n\u001B[1;32m      6\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mload_conte69\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      7\u001B[0m            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mload_fsa5\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      8\u001B[0m            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mload_mask\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     14\u001B[0m            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mload_confounds_preprocessing\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     15\u001B[0m            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfetch_timeseries_preprocessing\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/brainspace/datasets/base.py:6\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mvtk\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m vtkPolyDataNormals\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmesh\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmesh_io\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m read_surface\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmesh\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmesh_operations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m combine_surfaces\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mparcellation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m reduce_by_labels\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/brainspace/mesh/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (array_operations, mesh_elements, mesh_correspondence,\n\u001B[1;32m      2\u001B[0m                mesh_cluster, mesh_creation, mesh_operations, mesh_io)\n\u001B[1;32m      4\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124marray_operations\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      5\u001B[0m            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmesh_elements\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      6\u001B[0m            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmesh_correspondence\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      9\u001B[0m            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmesh_cluster\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     10\u001B[0m            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmesh_io\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/brainspace/mesh/array_operations.py:12\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstats\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mode\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mspatial\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KDTree\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msparse\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcsgraph\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m laplacian, connected_components\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/scipy/stats/__init__.py:605\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124;03m.. _statsrefmanual:\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    600\u001B[0m \n\u001B[1;32m    601\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m  \u001B[38;5;66;03m# noqa: E501\u001B[39;00m\n\u001B[1;32m    603\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_warnings_errors\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001B[1;32m    604\u001B[0m                                DegenerateDataWarning, FitError)\n\u001B[0;32m--> 605\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_stats_py\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m    606\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_variation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m variation\n\u001B[1;32m    607\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistributions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/scipy/stats/_stats_py.py:45\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mspecial\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mspecial\u001B[39;00m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m linalg\n\u001B[0;32m---> 45\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distributions\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _mstats_basic \u001B[38;5;28;01mas\u001B[39;00m mstats_basic\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_stats_mstats_common\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (_find_repeats, linregress, theilslopes,\n\u001B[1;32m     48\u001B[0m                                    siegelslopes)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/scipy/stats/distributions.py:8\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Author:  Travis Oliphant  2002-2011 with contributions from\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m#          SciPy Developers 2004-2011\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m#       instead of `git blame -Lxxx,+x`.\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_distn_infrastructure\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (rv_discrete, rv_continuous, rv_frozen)  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _continuous_distns\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _discrete_distns\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/scipy/stats/_distn_infrastructure.py:23\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mspecial\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m comb, entr\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# for root finding for continuous distribution ppf, and maximum likelihood\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# estimation\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m optimize\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# for functions of continuous distributions (e.g. moments, entropy, cdf)\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m integrate\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1075\u001B[0m, in \u001B[0;36m_handle_fromlist\u001B[0;34m(module, fromlist, import_, recursive)\u001B[0m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/scipy/__init__.py:134\u001B[0m, in \u001B[0;36m__getattr__\u001B[0;34m(name)\u001B[0m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getattr__\u001B[39m(name):\n\u001B[1;32m    133\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m submodules:\n\u001B[0;32m--> 134\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_importlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mscipy.\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mname\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    135\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    136\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/importlib/__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m    124\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/scipy/optimize/__init__.py:413\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124;03m=====================================================\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03mOptimization and root finding (:mod:`scipy.optimize`)\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    409\u001B[0m \n\u001B[1;32m    410\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m  \u001B[38;5;66;03m# noqa: E501\u001B[39;00m\n\u001B[1;32m    412\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_optimize\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m--> 413\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_minimize\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m    414\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_root\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_root_scalar\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/scipy/optimize/_minimize.py:30\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_trustregion_constr\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _minimize_trustregion_constr\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# constrained minimization\u001B[39;00m\n\u001B[0;32m---> 30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_lbfgsb_py\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _minimize_lbfgsb\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_tnc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _minimize_tnc\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_cobyla_py\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _minimize_cobyla\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:38\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m array, asarray, float64, zeros\n\u001B[0;32m---> 38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _lbfgsb\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_optimize\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (MemoizeJac, OptimizeResult, _call_callback_maybe_halt,\n\u001B[1;32m     40\u001B[0m                         _wrap_callback, _check_unknown_options,\n\u001B[1;32m     41\u001B[0m                         _prepare_scalar_function)\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_constraints\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m old_bound_to_new\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from brainspace.datasets import load_group_fc, load_parcellation, load_conte69\n",
    "\n",
    "# First load mean connectivity matrix and Schaefer parcellation\n",
    "conn_matrix = load_group_fc('schaefer', scale=400)\n",
    "labeling = load_parcellation('schaefer', scale=400, join=True)\n",
    "\n",
    "mask = labeling != 0\n",
    "\n",
    "# and load the conte69 hemisphere surfaces\n",
    "surf_lh, surf_rh = load_conte69()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GradientMaps object allows for many different kernels and dimensionality\n",
    "reduction techniques. Let’s have a look at three different kernels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T06:10:36.819989Z",
     "start_time": "2024-06-11T03:53:44.779475Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from brainspace.gradient import GradientMaps\n",
    "from brainspace.plotting import plot_hemispheres\n",
    "from brainspace.utils.parcellation import map_to_labels\n",
    "\n",
    "kernels = ['pearson', 'spearman', 'normalized_angle']\n",
    "\n",
    "gradients_kernel = [None] * len(kernels)\n",
    "for i, k in enumerate(kernels):\n",
    "    gm = GradientMaps(kernel=k, approach='dm', random_state=0)\n",
    "    gm.fit(conn_matrix)\n",
    "\n",
    "    gradients_kernel[i] = map_to_labels(gm.gradients_[:, i], labeling, mask=mask,\n",
    "                                        fill=np.nan)\n",
    "\n",
    "\n",
    "label_text = ['Pearson', 'Spearman', 'Normalized\\nAngle']\n",
    "plot_hemispheres(surf_lh, surf_rh, array_name=gradients_kernel, size=(1200, 600),\n",
    "                 cmap='viridis_r', color_bar=True, label_text=label_text, zoom=1.45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the gradients provided by these kernels are quite similar although\n",
    "their scaling is quite different. Do note that the gradients are in arbitrary\n",
    "units, so the smaller/larger axes across kernels do not imply anything.\n",
    "Similar to using different kernels, we can also use different dimensionality\n",
    "reduction techniques.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T06:16:49.620378Z",
     "start_time": "2024-06-11T06:16:05.297284Z"
    }
   },
   "outputs": [],
   "source": [
    "# PCA, Laplacian eigenmaps and diffusion mapping\n",
    "embeddings = ['pca', 'le', 'dm']\n",
    "\n",
    "gradients_embedding = [None] * len(embeddings)\n",
    "for i, emb in enumerate(embeddings):\n",
    "    gm = GradientMaps(kernel='normalized_angle', approach=emb, random_state=0)\n",
    "    gm.fit(conn_matrix)\n",
    "\n",
    "    gradients_embedding[i] = map_to_labels(gm.gradients_[:, 0], labeling, mask=mask,\n",
    "                                           fill=np.nan)\n",
    "\n",
    "\n",
    "label_text = ['PCA', 'LE', 'DM']\n",
    "plot_hemispheres(surf_lh, surf_rh, array_name=gradients_embedding, size=(1200, 600),\n",
    "                 cmap='viridis_r', color_bar=True, label_text=label_text, zoom=1.45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient alignment\n",
    "\n",
    "A more principled way of increasing comparability across gradients are\n",
    "alignment techniques. BrainSpace provides two alignment techniques:\n",
    "Procrustes analysis, and joint alignment. For this example we will load\n",
    "functional connectivity data of a second subject group and align it with the\n",
    "first group.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-11T06:17:00.218037Z",
     "start_time": "2024-06-11T06:16:58.253478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "GradientMaps(alignment='joint', kernel='normalized_angle')",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientMaps(alignment=&#x27;joint&#x27;, kernel=&#x27;normalized_angle&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientMaps</label><div class=\"sk-toggleable__content\"><pre>GradientMaps(alignment=&#x27;joint&#x27;, kernel=&#x27;normalized_angle&#x27;)</pre></div></div></div></div></div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_matrix2 = load_group_fc('schaefer', scale=400, group='holdout')\n",
    "gp = GradientMaps(kernel='normalized_angle', alignment='procrustes')\n",
    "gj = GradientMaps(kernel='normalized_angle', alignment='joint')\n",
    "\n",
    "gp.fit([conn_matrix, conn_matrix2])\n",
    "gj.fit([conn_matrix, conn_matrix2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `gp` contains the Procrustes aligned data and `gj` contains the joint\n",
    "aligned data. Let’s plot them, but in separate figures to keep things\n",
    "organized.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First gradient from original and holdout data, without alignment\n",
    "gradients_unaligned = [None] * 2\n",
    "for i in range(2):\n",
    "    gradients_unaligned[i] = map_to_labels(gp.gradients_[i][:, 0], labeling,\n",
    "                                           mask=mask, fill=np.nan)\n",
    "\n",
    "label_text = ['Unaligned\\nGroup 1', 'Unaligned\\nGroup 2']\n",
    "plot_hemispheres(surf_lh, surf_rh, array_name=gradients_unaligned, size=(1200, 400),\n",
    "                 cmap='viridis_r', color_bar=True, label_text=label_text, zoom=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# With procrustes alignment\n",
    "gradients_procrustes = [None] * 2\n",
    "for i in range(2):\n",
    "    gradients_procrustes[i] = map_to_labels(gp.aligned_[i][:, 0], labeling, mask=mask,\n",
    "                                            fill=np.nan)\n",
    "\n",
    "label_text = ['Procrustes\\nGroup 1', 'Procrustes\\nGroup 2']\n",
    "plot_hemispheres(surf_lh, surf_rh, array_name=gradients_procrustes, size=(1200, 400),\n",
    "                 cmap='viridis_r', color_bar=True, label_text=label_text, zoom=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# With joint alignment\n",
    "gradients_joint = [None] * 2\n",
    "for i in range(2):\n",
    "    gradients_joint[i] = map_to_labels(gj.aligned_[i][:, 0], labeling, mask=mask,\n",
    "                                       fill=np.nan)\n",
    "\n",
    "label_text = ['Joint\\nGroup 1', 'Joint\\nGroup 2']\n",
    "plot_hemispheres(surf_lh, surf_rh, array_name=gradients_joint, size=(1200, 400),\n",
    "                 cmap='viridis_r', color_bar=True, label_text=label_text, zoom=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although in this example, we don't see any big differences, if the input data\n",
    "was less similar, alignments may also resolve changes in the order of the\n",
    "gradients. However, you should always inspect the output of an alignment;\n",
    "if the input data are sufficiently dissimilar then the alignment may produce\n",
    "odd results.\n",
    "\n",
    "\n",
    "In some instances, you may want to align gradients to an out-of-sample\n",
    "gradient, for example when aligning individuals to a hold-out group gradient.\n",
    "When performing a Procrustes alignemnt, a 'reference' can be specified.\n",
    "The first alignment iteration will then be to the reference. For purposes of\n",
    "this example, we will use the gradient of the hold-out group as the\n",
    "reference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gref = GradientMaps(kernel='normalized_angle', approach='le')\n",
    "gref.fit(conn_matrix2)\n",
    "\n",
    "galign = GradientMaps(kernel='normalized_angle', approach='le', alignment='procrustes')\n",
    "galign.fit(conn_matrix, reference=gref.gradients_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradients in `galign.aligned_` are now aligned to the reference\n",
    "gradients.\n",
    "\n",
    "## Gradient fusion\n",
    "We can also fuse data across multiple modalities and build mutli-modal\n",
    "gradients. In this case we only look at one set of output gradients,\n",
    "rather than one per modality.\n",
    "\n",
    "First, let's load the example data of microstructural profile covariance\n",
    "`(Paquola et al., 2019) <https://journals.plos.org/plosbiology/article?\n",
    "id=10.1371/journal.pbio.3000284>`_ and functional connectivity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from brainspace.datasets import load_group_mpc\n",
    "\n",
    "# First load mean connectivity matrix and parcellation\n",
    "fc = load_group_fc('vosdewael', scale=200)\n",
    "mpc = load_group_mpc('vosdewael', scale=200)\n",
    "\n",
    "labeling = load_parcellation('vosdewael', scale=200, join=True)\n",
    "mask = labeling != 0\n",
    "\n",
    "seeds = [None] * 2\n",
    "seeds[0] = map_to_labels(fc[0], labeling, mask=mask, fill=np.nan)\n",
    "seeds[1] = map_to_labels(mpc[0], labeling, mask=mask, fill=np.nan)\n",
    "\n",
    "# visualise the features from a seed region (seed 0)\n",
    "plot_hemispheres(surf_lh, surf_rh, array_name=seeds, label_text=['FC', 'MPC'],\n",
    "                 size=(1200, 400), color_bar=True, cmap='viridis', zoom=1.45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fuse the matrices, we simply pass the matrices to the fusion\n",
    "command which will rescale and horizontally concatenate the matrices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Negative numbers are not allowed in fusion.\n",
    "fc[fc < 0] = 0\n",
    "\n",
    "\n",
    "def fusion(*args):\n",
    "    from scipy.stats import rankdata\n",
    "    from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "    max_rk = [None] * len(args)\n",
    "    masks = [None] * len(args)\n",
    "    for j, a in enumerate(args):\n",
    "        m = masks[j] = a != 0\n",
    "        a[m] = rankdata(a[m])\n",
    "        max_rk[j] = a[m].max()\n",
    "\n",
    "    max_rk = min(max_rk)\n",
    "    for j, a in enumerate(args):\n",
    "        m = masks[j]\n",
    "        a[m] = minmax_scale(a[m], feature_range=(1, max_rk))\n",
    "\n",
    "    return np.hstack(args)\n",
    "\n",
    "\n",
    "# fuse the matrices\n",
    "fused_matrix = fusion(fc, mpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use this output in the fit function. This will convert the long\n",
    "horizontal array into a square affinity matrix, and then perform embedding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gm = GradientMaps(n_components=2, kernel='normalized_angle')\n",
    "gm.fit(fused_matrix)\n",
    "\n",
    "\n",
    "gradients_fused = [None] * 2\n",
    "for i in range(2):\n",
    "    gradients_fused[i] = map_to_labels(gm.gradients_[:, i], labeling, mask=mask,\n",
    "                                       fill=np.nan)\n",
    "\n",
    "plot_hemispheres(surf_lh, surf_rh, array_name=gradients_fused,\n",
    "                 label_text=['Gradient 1', 'Gradient 2'], size=(1200, 400),\n",
    "                 color_bar=True, cmap='viridis', zoom=1.45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>The mpc matrix presented here matches the subject cohort of `(Paquola et\n",
    "  al., 2019) <https://journals.plos.org/plosbiology/article?id=10.1371/\n",
    "  journal.pbio.3000284>`_. Other matrices in this package match the subject\n",
    "  groups used by `(Vos de Wael et al., 2018) <https://www.pnas.org/content/\n",
    "  115/40/10154.short>`_. We make direct comparisons in our tutorial for\n",
    "  didactic purposes only.</p></div>\n",
    "\n",
    "That concludes the second tutorial. In the third tutorial we will consider\n",
    "null hypothesis testing of comparisons between gradients and other markers.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
